{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:14:11.991357Z",
     "start_time": "2024-11-15T20:14:07.505974Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def merge_sector_data(mkt_cap_dir, revenue_dir):\n",
    "    \"\"\"\n",
    "    Merge market cap and revenue data for sectors where both datasets are available.\n",
    "    Handles specific CSV structures with quarterly market cap and yearly revenue data.\n",
    "    \"\"\"\n",
    "    merged_sectors = {}\n",
    "    \n",
    "    # Get list of sectors from both directories\n",
    "    mkt_cap_sectors = {f.split('_mkt_cap')[0] for f in os.listdir(mkt_cap_dir) if f.endswith('.csv')}\n",
    "    revenue_sectors = {f.split('_revenue')[0] for f in os.listdir(revenue_dir) if f.endswith('.csv')}\n",
    "    \n",
    "    # Find common sectors\n",
    "    common_sectors = mkt_cap_sectors.intersection(revenue_sectors)\n",
    "    \n",
    "    for sector in common_sectors:\n",
    "        print(f\"Processing sector: {sector}\")\n",
    "        \n",
    "        # Read market cap data\n",
    "        mkt_cap_file = f\"{sector}_mkt_cap_quarter_end.csv\"\n",
    "        mkt_cap_path = os.path.join(mkt_cap_dir, mkt_cap_file)\n",
    "        mkt_cap_df = pd.read_csv(mkt_cap_path)\n",
    "        \n",
    "        # Read revenue data\n",
    "        revenue_file = f\"{sector}_revenue.csv\"\n",
    "        revenue_path = os.path.join(revenue_dir, revenue_file)\n",
    "        revenue_df = pd.read_csv(revenue_path)\n",
    "        \n",
    "        # Clean and convert dates\n",
    "        try:\n",
    "            # Handle the specific date format in market cap data\n",
    "            mkt_cap_df['Date'] = pd.to_datetime(mkt_cap_df['Date'].str.split(' ').str[0])\n",
    "        except AttributeError:\n",
    "            # If the date is already in a different format\n",
    "            mkt_cap_df['Date'] = pd.to_datetime(mkt_cap_df['Date'])\n",
    "            \n",
    "        revenue_df['date'] = pd.to_datetime(revenue_df['date'])\n",
    "        \n",
    "        # Extract year and quarter\n",
    "        mkt_cap_df['year'] = pd.DatetimeIndex(mkt_cap_df['Date']).year\n",
    "        mkt_cap_df['quarter'] = pd.DatetimeIndex(mkt_cap_df['Date']).quarter\n",
    "        \n",
    "        # Create a list to store merged data for each ticker\n",
    "        merged_data = []\n",
    "        \n",
    "        # Get unique tickers from both datasets\n",
    "        # Convert ticker columns to uppercase for consistent matching\n",
    "        mkt_cap_df['Ticker'] = mkt_cap_df['Ticker'].str.upper()\n",
    "        revenue_df['ticker'] = revenue_df['ticker'].str.upper()\n",
    "        \n",
    "        common_tickers = set(mkt_cap_df['Ticker']).intersection(set(revenue_df['ticker']))\n",
    "        \n",
    "        print(f\"Found {len(common_tickers)} common tickers for {sector}\")\n",
    "        \n",
    "        for ticker in common_tickers:\n",
    "            # Filter data for current ticker\n",
    "            ticker_mkt_cap = mkt_cap_df[mkt_cap_df['Ticker'] == ticker].copy()\n",
    "            ticker_revenue = revenue_df[revenue_df['ticker'] == ticker].copy()\n",
    "            \n",
    "            # For each market cap entry, find the corresponding revenue\n",
    "            for _, mkt_cap_row in ticker_mkt_cap.iterrows():\n",
    "                matching_revenue = ticker_revenue[\n",
    "                    (ticker_revenue['year'] == mkt_cap_row['year']) &\n",
    "                    (ticker_revenue['quarter'] == mkt_cap_row['quarter'])\n",
    "                ]\n",
    "                \n",
    "                if matching_revenue.empty:\n",
    "                    # If no quarterly match, get the yearly revenue\n",
    "                    yearly_revenue = ticker_revenue[\n",
    "                        ticker_revenue['year'] == mkt_cap_row['year']\n",
    "                    ]\n",
    "                    \n",
    "                    if not yearly_revenue.empty:\n",
    "                        # Take the last available revenue entry for the year\n",
    "                        revenue_value = yearly_revenue.iloc[-1]['revenue']\n",
    "                        revenue_growth = yearly_revenue.iloc[-1].get('revenue_yoy_growth', np.nan)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    revenue_value = matching_revenue.iloc[0]['revenue']\n",
    "                    revenue_growth = matching_revenue.iloc[0].get('revenue_yoy_growth', np.nan)\n",
    "                \n",
    "                # Create merged row\n",
    "                merged_row = {\n",
    "                    'Date': mkt_cap_row['Date'],\n",
    "                    'Year': mkt_cap_row['year'],\n",
    "                    'Quarter': mkt_cap_row['quarter'],\n",
    "                    'Ticker': ticker,\n",
    "                    'MarketCap': mkt_cap_row['MarketCap'],\n",
    "                    'Revenue': revenue_value,\n",
    "                    'Revenue_YoY_Growth': revenue_growth,\n",
    "                    'Company_Name': ticker_revenue.iloc[0].get('company_name', ticker)\n",
    "                }\n",
    "                merged_data.append(merged_row)\n",
    "        \n",
    "        if merged_data:\n",
    "            # Create DataFrame from merged data\n",
    "            merged_df = pd.DataFrame(merged_data)\n",
    "            # Sort by Date and Ticker\n",
    "            merged_df = merged_df.sort_values(['Date', 'Ticker'])\n",
    "            merged_sectors[sector] = merged_df\n",
    "            print(f\"Successfully merged data for {sector}\")\n",
    "        else:\n",
    "            print(f\"No matching data found for {sector}\")\n",
    "        \n",
    "    return merged_sectors\n",
    "\n",
    "\n",
    "\n",
    "def calculate_growth_indicator(value):\n",
    "    \"\"\"Convert growth percentage to indicator: 1 (>5%), -1 (<-5%), 0 (between -5% and 5%)\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    if value > 5:\n",
    "        return 1\n",
    "    elif value < -5:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_beta_covariance(df, period_months):\n",
    "    \"\"\"Calculate covariance of beta over specified period\"\"\"\n",
    "    try:\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Calculate returns for market cap\n",
    "        df['Returns'] = df.groupby('Ticker')['MarketCap'].pct_change()\n",
    "        \n",
    "        # Calculate market returns (using average of all companies as market proxy)\n",
    "        df['Market_Returns'] = df.groupby('Date')['Returns'].transform('mean')\n",
    "        \n",
    "        # Calculate rolling beta for each ticker\n",
    "        rolling_window = period_months * 3  # Assuming quarterly data\n",
    "        \n",
    "        # Initialize empty list to store betas for each ticker\n",
    "        all_betas = []\n",
    "        \n",
    "        for ticker in df['Ticker'].unique():\n",
    "            ticker_data = df[df['Ticker'] == ticker].copy()\n",
    "            if len(ticker_data) > rolling_window:\n",
    "                # Calculate rolling correlation\n",
    "                rolling_cov = ticker_data['Returns'].rolling(window=rolling_window).cov(ticker_data['Market_Returns'])\n",
    "                rolling_var = ticker_data['Market_Returns'].rolling(window=rolling_window).var()\n",
    "                ticker_data['Beta'] = rolling_cov / rolling_var\n",
    "                all_betas.append(ticker_data[['Date', 'Beta']].dropna())\n",
    "        \n",
    "        if not all_betas:\n",
    "            return 0\n",
    "            \n",
    "        # Combine all betas\n",
    "        all_betas_df = pd.concat(all_betas)\n",
    "        \n",
    "        # Calculate covariance matrix of betas between different dates\n",
    "        beta_matrix = all_betas_df.pivot(columns='Date', values='Beta')\n",
    "        cov_matrix = beta_matrix.cov()\n",
    "        \n",
    "        # Return average of covariance matrix (excluding diagonal)\n",
    "        mask = ~np.eye(cov_matrix.shape[0], dtype=bool)\n",
    "        return np.abs(cov_matrix.where(mask).mean().mean())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating beta covariance: {e}\")\n",
    "        return 0\n",
    "\n",
    "def calculate_sector_rankings(merged_sectors, output_file='sector_rankings.csv'):\n",
    "    \"\"\"Calculate and rank sectors based on the five specified parameters\"\"\"\n",
    "    rankings = []\n",
    "    \n",
    "    for sector, df in merged_sectors.items():\n",
    "        print(f\"Calculating rankings for sector: {sector}\")\n",
    "        try:\n",
    "            # 1. Market Cap YoY Growth Indicator\n",
    "            df['MktCap_YoY_Change'] = df.groupby('Ticker')['MarketCap'].pct_change(periods=4) * 100\n",
    "            df['MktCap_Growth_Indicator'] = df['MktCap_YoY_Change'].apply(calculate_growth_indicator)\n",
    "            \n",
    "            # 2. Revenue YoY Growth Indicator\n",
    "            df['Revenue_Growth_Indicator'] = df['Revenue_YoY_Growth'].apply(calculate_growth_indicator)\n",
    "            \n",
    "            # 3. Variance between weighted and simple average\n",
    "            df['Weighted_MktCap_Change'] = (\n",
    "                df['MktCap_YoY_Change'] * \n",
    "                df['MarketCap'] / \n",
    "                df.groupby('Date')['MarketCap'].transform('sum')\n",
    "            )\n",
    "            weighted_avg = df.groupby('Date')['Weighted_MktCap_Change'].sum().mean()\n",
    "            simple_avg = df['MktCap_YoY_Change'].mean()\n",
    "            variance_avg = abs(weighted_avg - simple_avg)\n",
    "            \n",
    "            # 4. 6-month beta covariance\n",
    "            beta_6m_cov = calculate_beta_covariance(df, 2)  # 2 quarters = 6 months\n",
    "            \n",
    "            # 5. 5-year beta covariance\n",
    "            beta_5y_cov = calculate_beta_covariance(df, 20)  # 20 quarters = 5 years\n",
    "            \n",
    "            rankings.append({\n",
    "                'Sector': sector,\n",
    "                'MktCap_Growth_Score': df['MktCap_Growth_Indicator'].mean(),\n",
    "                'Revenue_Growth_Score': df['Revenue_Growth_Indicator'].mean(),\n",
    "                'Weighted_Simple_Variance': variance_avg,\n",
    "                'Beta_6M_Covariance': beta_6m_cov,\n",
    "                'Beta_5Y_Covariance': beta_5y_cov,\n",
    "                'Number_of_Companies': len(df['Ticker'].unique())\n",
    "            })\n",
    "            print(f\"Successfully calculated rankings for {sector}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sector {sector}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create rankings DataFrame and save to CSV\n",
    "    rankings_df = pd.DataFrame(rankings)\n",
    "    rankings_df.to_csv(output_file, index=False)\n",
    "    return rankings_df\n",
    "\n",
    "def main():\n",
    "    mkt_cap_dir = \"sector_mkt_cap_results\"\n",
    "    revenue_dir = \"sector_revenue_results\"\n",
    "    \n",
    "    # Merge sector data\n",
    "    merged_sectors = merge_sector_data(mkt_cap_dir, revenue_dir)\n",
    "    \n",
    "    # Calculate rankings with new parameters\n",
    "    rankings_df = calculate_sector_rankings(merged_sectors)\n",
    "    \n",
    "    # Print rankings for each parameter\n",
    "    parameters = ['MktCap_Growth_Score', 'Revenue_Growth_Score', 'Weighted_Simple_Variance', \n",
    "                 'Beta_6M_Covariance', 'Beta_5Y_Covariance']\n",
    "    \n",
    "    for param in parameters:\n",
    "        print(f\"\\nRanking of sectors based on {param}:\")\n",
    "        sorted_rankings = rankings_df.sort_values(param, ascending=False)\n",
    "        for _, row in sorted_rankings.iterrows():\n",
    "            print(f\"{row['Sector']} ({row['Number_of_Companies']} companies): {row[param]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:14:17.464068Z",
     "start_time": "2024-11-15T20:14:12.005212Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def merge_sector_data(mkt_cap_dir, revenue_dir, output_dir=\"merged_sector_data\"):\n",
    "    \"\"\"\n",
    "    Merge market cap and revenue data for sectors where both datasets are available.\n",
    "    Handles specific CSV structures with quarterly market cap and yearly revenue data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    merged_sectors = {}\n",
    "    \n",
    "    # Get list of sectors from both directories\n",
    "    mkt_cap_sectors = {f.split('_mkt_cap')[0] for f in os.listdir(mkt_cap_dir) if f.endswith('.csv')}\n",
    "    revenue_sectors = {f.split('_revenue')[0] for f in os.listdir(revenue_dir) if f.endswith('.csv')}\n",
    "    \n",
    "    # Find common sectors\n",
    "    common_sectors = mkt_cap_sectors.intersection(revenue_sectors)\n",
    "    \n",
    "    for sector in common_sectors:\n",
    "        print(f\"Processing sector: {sector}\")\n",
    "        \n",
    "        # Read market cap data\n",
    "        mkt_cap_file = f\"{sector}_mkt_cap_quarter_end.csv\"\n",
    "        mkt_cap_path = os.path.join(mkt_cap_dir, mkt_cap_file)\n",
    "        mkt_cap_df = pd.read_csv(mkt_cap_path)\n",
    "        \n",
    "        # Read revenue data\n",
    "        revenue_file = f\"{sector}_revenue.csv\"\n",
    "        revenue_path = os.path.join(revenue_dir, revenue_file)\n",
    "        revenue_df = pd.read_csv(revenue_path)\n",
    "        \n",
    "        # Clean and convert dates\n",
    "        try:\n",
    "            # Handle the specific date format in market cap data\n",
    "            mkt_cap_df['Date'] = pd.to_datetime(mkt_cap_df['Date'].str.split(' ').str[0])\n",
    "        except AttributeError:\n",
    "            mkt_cap_df['Date'] = pd.to_datetime(mkt_cap_df['Date'])\n",
    "            \n",
    "        revenue_df['date'] = pd.to_datetime(revenue_df['date'])\n",
    "        \n",
    "        # Extract year and quarter\n",
    "        mkt_cap_df['year'] = pd.DatetimeIndex(mkt_cap_df['Date']).year\n",
    "        mkt_cap_df['quarter'] = pd.DatetimeIndex(mkt_cap_df['Date']).quarter\n",
    "        \n",
    "        # Create a list to store merged data for each ticker\n",
    "        merged_data = []\n",
    "        \n",
    "        # Get unique tickers from both datasets\n",
    "        mkt_cap_df['Ticker'] = mkt_cap_df['Ticker'].str.upper()\n",
    "        revenue_df['ticker'] = revenue_df['ticker'].str.upper()\n",
    "        \n",
    "        common_tickers = set(mkt_cap_df['Ticker']).intersection(set(revenue_df['ticker']))\n",
    "        \n",
    "        print(f\"Found {len(common_tickers)} common tickers for {sector}\")\n",
    "        \n",
    "        for ticker in common_tickers:\n",
    "            ticker_mkt_cap = mkt_cap_df[mkt_cap_df['Ticker'] == ticker].copy()\n",
    "            ticker_revenue = revenue_df[revenue_df['ticker'] == ticker].copy()\n",
    "            \n",
    "            for _, mkt_cap_row in ticker_mkt_cap.iterrows():\n",
    "                matching_revenue = ticker_revenue[\n",
    "                    (ticker_revenue['year'] == mkt_cap_row['year']) &\n",
    "                    (ticker_revenue['quarter'] == mkt_cap_row['quarter'])\n",
    "                ]\n",
    "                \n",
    "                if matching_revenue.empty:\n",
    "                    yearly_revenue = ticker_revenue[\n",
    "                        ticker_revenue['year'] == mkt_cap_row['year']\n",
    "                    ]\n",
    "                    if not yearly_revenue.empty:\n",
    "                        revenue_value = yearly_revenue.iloc[-1]['revenue']\n",
    "                        revenue_growth = yearly_revenue.iloc[-1].get('revenue_yoy_growth', np.nan)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    revenue_value = matching_revenue.iloc[0]['revenue']\n",
    "                    revenue_growth = matching_revenue.iloc[0].get('revenue_yoy_growth', np.nan)\n",
    "                \n",
    "                merged_row = {\n",
    "                    'Date': mkt_cap_row['Date'],\n",
    "                    'Year': mkt_cap_row['year'],\n",
    "                    'Quarter': mkt_cap_row['quarter'],\n",
    "                    'Ticker': ticker,\n",
    "                    'MarketCap': mkt_cap_row['MarketCap'],\n",
    "                    'Revenue': revenue_value,\n",
    "                    'Revenue_YoY_Growth': revenue_growth,\n",
    "                    'Company_Name': ticker_revenue.iloc[0].get('company_name', ticker)\n",
    "                }\n",
    "                merged_data.append(merged_row)\n",
    "        \n",
    "        if merged_data:\n",
    "            merged_df = pd.DataFrame(merged_data)\n",
    "            merged_df = merged_df.sort_values(['Date', 'Ticker'])\n",
    "            merged_sectors[sector] = merged_df\n",
    "            \n",
    "            # Save merged data to a CSV file\n",
    "            output_file_path = os.path.join(output_dir, f\"{sector}_merged_data.csv\")\n",
    "            merged_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Successfully merged data for {sector} and saved to {output_file_path}\")\n",
    "        else:\n",
    "            print(f\"No matching data found for {sector}\")\n",
    "        \n",
    "    return merged_sectors\n",
    "\n",
    "def calculate_growth_indicator(value):\n",
    "    \"\"\"Convert growth percentage to indicator: 1 (>5%), -1 (<-5%), 0 (between -5% and 5%)\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    if value > 5:\n",
    "        return 1\n",
    "    elif value < -5:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_beta_covariance(df, period_months):\n",
    "    \"\"\"\n",
    "    Calculate covariance of beta over a specified period with improved handling of time series.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Ensure data is sorted by date\n",
    "        df = df.sort_values(['Date', 'Ticker'])\n",
    "        \n",
    "        # Calculate returns for each company\n",
    "        df['Returns'] = df.groupby('Ticker')['MarketCap'].pct_change()\n",
    "        \n",
    "        # Calculate market returns (using value-weighted market return)\n",
    "        df['Market_Value'] = df.groupby('Date')['MarketCap'].transform('sum')\n",
    "        df['Market_Weight'] = df['MarketCap'] / df['Market_Value']\n",
    "        df['Market_Returns'] = df.groupby('Date')['Returns'].transform(lambda x: (x * df.loc[x.index, 'Market_Weight']).sum())\n",
    "        \n",
    "        # Set minimum periods for rolling calculations\n",
    "        min_periods = max(2, period_months - 1)  # Ensure at least 2 periods for correlation\n",
    "        rolling_window = period_months * 3  # Convert months to quarters (assuming quarterly data)\n",
    "        \n",
    "        betas_by_date = []\n",
    "        \n",
    "        for ticker in df['Ticker'].unique():\n",
    "            ticker_data = df[df['Ticker'] == ticker].copy()\n",
    "            \n",
    "            if len(ticker_data) >= min_periods:\n",
    "                # Calculate rolling betas\n",
    "                rolling_cov = (\n",
    "                    ticker_data['Returns']\n",
    "                    .rolling(window=rolling_window, min_periods=min_periods)\n",
    "                    .cov(ticker_data['Market_Returns'])\n",
    "                )\n",
    "                \n",
    "                rolling_market_var = (\n",
    "                    ticker_data['Market_Returns']\n",
    "                    .rolling(window=rolling_window, min_periods=min_periods)\n",
    "                    .var()\n",
    "                )\n",
    "                \n",
    "                # To avoid dividing by zero, handle NaN or zero variance values\n",
    "                ticker_data['Beta'] = rolling_cov / rolling_market_var.replace(0, np.nan)\n",
    "                \n",
    "                # Store results\n",
    "                betas_by_date.append(ticker_data[['Date', 'Ticker', 'Beta']].dropna())\n",
    "        \n",
    "        if not betas_by_date:\n",
    "            return 0\n",
    "        \n",
    "        # Combine all beta calculations\n",
    "        all_betas = pd.concat(betas_by_date)\n",
    "        \n",
    "        # Create a pivot table of betas (companies x dates)\n",
    "        beta_matrix = all_betas.pivot_table(\n",
    "            index='Ticker',\n",
    "            columns='Date',\n",
    "            values='Beta',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        # Remove companies with too many missing values\n",
    "        min_observations = beta_matrix.shape[1] * 0.5  # Require at least 50% of dates\n",
    "        beta_matrix = beta_matrix[beta_matrix.count(axis=1) >= min_observations]\n",
    "        \n",
    "        if beta_matrix.empty:\n",
    "            return 0\n",
    "        \n",
    "        # Fill remaining NaN values with forward fill then backward fill\n",
    "        beta_matrix = beta_matrix.fillna(method='ffill', axis=1).fillna(method='bfill', axis=1)\n",
    "        \n",
    "        # Calculate covariance between different dates\n",
    "        cov_matrix = beta_matrix.T.cov()\n",
    "        \n",
    "        # Calculate average absolute covariance (excluding diagonal)\n",
    "        mask = ~np.eye(cov_matrix.shape[0], dtype=bool)\n",
    "        avg_cov = np.abs(cov_matrix.where(mask)).mean().mean()\n",
    "        \n",
    "        return float(avg_cov) if not np.isnan(avg_cov) else 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in beta covariance calculation: {e}\")\n",
    "        return 0\n",
    "\n",
    "def calculate_sector_rankings(merged_sectors, output_file='sector_rankings.csv'):\n",
    "    \"\"\"Calculate and rank sectors based on the five specified parameters\"\"\"\n",
    "    rankings = []\n",
    "    \n",
    "    for sector, df in merged_sectors.items():\n",
    "        print(f\"Processing sector: {sector}\")\n",
    "        try:\n",
    "            # Ensure data is sorted chronologically\n",
    "            df = df.sort_values('Date')\n",
    "            \n",
    "            # 1. Market Cap YoY Growth Indicator\n",
    "            df['MktCap_YoY_Change'] = df.groupby('Ticker')['MarketCap'].pct_change(periods=4) * 100\n",
    "            df['MktCap_Growth_Indicator'] = df['MktCap_YoY_Change'].apply(calculate_growth_indicator)\n",
    "            \n",
    "            # 2. Revenue YoY Growth Indicator\n",
    "            df['Revenue_Growth_Indicator'] = df['Revenue_YoY_Growth'].apply(calculate_growth_indicator)\n",
    "            \n",
    "            # 3. Variance between weighted and simple average\n",
    "            df['Weighted_MktCap_Change'] = (\n",
    "                df['MktCap_YoY_Change'] * \n",
    "                df['MarketCap'] / \n",
    "                df.groupby('Date')['MarketCap'].transform('sum')\n",
    "            )\n",
    "            \n",
    "            # Calculate averages only for non-NaN values\n",
    "            weighted_avg = df.groupby('Date')['Weighted_MktCap_Change'].sum().mean()\n",
    "            simple_avg = df['MktCap_YoY_Change'].mean()\n",
    "            variance_avg = abs(weighted_avg - simple_avg)\n",
    "            \n",
    "            # 4 & 5. Beta covariances\n",
    "            print(f\"Calculating 6-month beta covariance for {sector}\")\n",
    "            beta_6m_cov = calculate_beta_covariance(df, 2)\n",
    "            \n",
    "            print(f\"Calculating 5-year beta covariance for {sector}\")\n",
    "            beta_4y_cov = calculate_beta_covariance(df, 16)\n",
    "            \n",
    "            rankings.append({\n",
    "                'Sector': sector,\n",
    "                'MktCap_Growth_Score': df['MktCap_Growth_Indicator'].mean(),\n",
    "                'Revenue_Growth_Score': df['Revenue_Growth_Indicator'].mean(),\n",
    "                'Weighted_Simple_Variance': variance_avg,\n",
    "                'Beta_6M_Covariance': beta_6m_cov,\n",
    "                'Beta_4Y_Covariance': beta_4y_cov,\n",
    "                'Number_of_Companies': len(df['Ticker'].unique()),\n",
    "                'Date_Range': f\"{df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\"\n",
    "            })\n",
    "            \n",
    "            print(f\"Successfully processed {sector}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sector {sector}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create rankings DataFrame and save to CSV\n",
    "    rankings_df = pd.DataFrame(rankings)\n",
    "    rankings_df.to_csv(output_file, index=False)\n",
    "    return rankings_df\n",
    "\n",
    "def main():\n",
    "    mkt_cap_dir = \"sector_mkt_cap_results\"\n",
    "    revenue_dir = \"sector_revenue_results\"\n",
    "    \n",
    "    # Merge sector data\n",
    "    merged_sectors = merge_sector_data(mkt_cap_dir, revenue_dir)\n",
    "    \n",
    "    # Calculate rankings with new parameters\n",
    "    rankings_df = calculate_sector_rankings(merged_sectors)\n",
    "    \n",
    "    # Print rankings for each parameter\n",
    "    parameters = ['MktCap_Growth_Score', 'Revenue_Growth_Score', 'Weighted_Simple_Variance', \n",
    "                 'Beta_6M_Covariance', 'Beta_4Y_Covariance']\n",
    "    \n",
    "    for param in parameters:\n",
    "        print(f\"\\nRanking of sectors based on {param}:\")\n",
    "        sorted_rankings = rankings_df.sort_values(param, ascending=False)\n",
    "        for _, row in sorted_rankings.iterrows():\n",
    "            print(f\"{row['Sector']} ({row['Number_of_Companies']} companies): {row[param]:.4f}\")\n",
    "            print(f\"Date Range: {row['Date_Range']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulas Used in Sector Analysis:\n",
    "\n",
    "1. Market Cap Growth Score:\n",
    "   - YoY Growth % = ((Current Quarter Market Cap - Same Quarter Last Year Market Cap) / Same Quarter Last Year Market Cap) * 100\n",
    "   - Score: 1 if growth > 5%, -1 if growth < -5%, 0 if -5% ≤ growth ≤ 5%\n",
    "   - Final Score = Average of all company scores in sector\n",
    "\n",
    "2. Revenue Growth Score:\n",
    "   - YoY Growth % = ((Current Year Revenue - Previous Year Revenue) / Previous Year Revenue) * 100\n",
    "   - Score: 1 if growth > 5%, -1 if growth < -5%, 0 if -5% ≤ growth ≤ 5%\n",
    "   - Final Score = Average of all company scores in sector\n",
    "\n",
    "3. Weighted vs Simple Average Variance:\n",
    "   - Weighted Average = Σ(Company Growth * (Company Market Cap / Total Sector Market Cap))\n",
    "   - Simple Average = Σ(Company Growth) / Number of Companies\n",
    "   - Variance = |Weighted Average - Simple Average|\n",
    "\n",
    "4. Beta Covariance Calculation:\n",
    "   - Company Returns = (Current Market Cap - Previous Market Cap) / Previous Market Cap\n",
    "   - Market Returns = Σ(Company Returns * Company Market Cap) / Total Market Cap\n",
    "   - Rolling Beta = Cov(Company Returns, Market Returns) / Var(Market Returns)\n",
    "   - Covariance = Average absolute covariance between different time periods' betas\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
