{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:11:47.273929Z",
     "start_time": "2024-11-15T20:03:14.399108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import certifi\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "COMPANY_DIR = \"company_revenue_results\"\n",
    "\n",
    "# List of API keys to rotate between\n",
    "API_KEYS = [\"iq6DT26XPhKSubtLN7RUaavctUknriHy\", \"U2liplE4h7atJ1E9iAirE2cdCtxMi8Ve\", \"6wGoNRskPwA23aw0EMgWEN1JDRRVcY8M\"]\n",
    "CALL_LIMIT_PER_KEY = 200  # Each API key has a limit of 250 calls per day\n",
    "\n",
    "# Initialize counters for API key usage\n",
    "api_call_counters = [0] * len(API_KEYS)\n",
    "current_key_index = 0\n",
    "\n",
    "def get_current_api_key():\n",
    "    global current_key_index\n",
    "    global api_call_counters\n",
    "    \n",
    "    # Rotate to the next API key if the current one reaches its limit\n",
    "    if api_call_counters[current_key_index] >= CALL_LIMIT_PER_KEY:\n",
    "        current_key_index = (current_key_index + 1) % len(API_KEYS)\n",
    "    \n",
    "    # Increment the call counter for the current key\n",
    "    api_call_counters[current_key_index] += 1\n",
    "    \n",
    "    # Return the current API key\n",
    "    return API_KEYS[current_key_index]\n",
    "\n",
    "def scrape_wikipedia_sp500():\n",
    "    \"\"\"Scrape S&P 500 companies and their sectors from Wikipedia.\"\"\"\n",
    "    response = requests.get(WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "    \n",
    "    companies_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        ticker = cols[0].text.strip()\n",
    "        company_name = cols[1].text.strip()\n",
    "        sector = cols[3].text.strip()\n",
    "        companies_data.append((ticker, company_name, sector))\n",
    "    \n",
    "    return companies_data\n",
    "\n",
    "def get_jsonparsed_data(url):\n",
    "    response = urlopen(url, cafile=certifi.where())\n",
    "    data = response.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "\n",
    "def get_quarterly_revenue(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch and process quarterly revenue data from Financial Modeling Prep API.\n",
    "    \"\"\"\n",
    "    api_key = get_current_api_key()  # Get the current API key\n",
    "    base_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{symbol}\"\n",
    "    url = f\"{base_url}?period=annual&limit=400&apikey={api_key}\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        data = get_jsonparsed_data(url)\n",
    "        if not data:\n",
    "            return None\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convert date column and set as index\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Filter date range\n",
    "        mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "        df = df[mask].copy()\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Extract quarter and year\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['year'] = df['date'].dt.year\n",
    "        \n",
    "        # Calculate YoY growth\n",
    "        df['revenue_yoy_growth'] = df.groupby('quarter')['revenue'].pct_change(4) * 100\n",
    "        \n",
    "        # Format results\n",
    "        result_df = df[['date', 'quarter', 'year', 'revenue', 'revenue_yoy_growth']].copy()\n",
    "        result_df['revenue'] = result_df['revenue'].round(2)\n",
    "        result_df['revenue_yoy_growth'] = result_df['revenue_yoy_growth'].round(2)\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_company_revenue(ticker, company_name, start_date, end_date):\n",
    "    \"\"\"Process revenue data for a company and save it.\"\"\"\n",
    "    company_revenue_df = get_quarterly_revenue(ticker, start_date, end_date)\n",
    "    \n",
    "    if company_revenue_df is not None:\n",
    "        company_revenue_df['ticker'] = ticker\n",
    "        company_revenue_df['company_name'] = company_name\n",
    "        \n",
    "        # Save the company data as soon as processed\n",
    "        csv_filename = os.path.join(COMPANY_DIR, f\"{ticker}_revenue.csv\")\n",
    "        \n",
    "        company_revenue_df.to_csv(csv_filename, index=False, mode='w', header=True)  # Write data to CSV\n",
    "        print(f\"Saved revenue data for {ticker} to {csv_filename}\")\n",
    "    else:\n",
    "        print(f\"No data found for {ticker}.\")\n",
    "\n",
    "def main():\n",
    "    os.makedirs(COMPANY_DIR, exist_ok=True)\n",
    "    \n",
    "    # Scrape SP500 companies and their sectors\n",
    "    companies_data = scrape_wikipedia_sp500()\n",
    "\n",
    "    # Define start and end dates for revenue data\n",
    "    start_date = \"2015-01-01\"\n",
    "    end_date = \"2024-06-30\"\n",
    "    \n",
    "    # Process each company\n",
    "    for ticker, company_name, sector in companies_data:\n",
    "        print(f\"\\nProcessing company: {company_name} ({ticker})\")\n",
    "        process_company_revenue(ticker, company_name, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
