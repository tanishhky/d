{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.043139Z",
     "start_time": "2024-11-15T19:55:48.037583Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.064660Z",
     "start_time": "2024-11-15T19:55:48.060173Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "    print(data.head())  # Print the first few rows to inspect the data\n",
    "    print(data.index)   # Print the index to check its type and format\n",
    "\n",
    "    # Convert timezone-aware datetime to naive datetime\n",
    "    if data.index.tz is not None:\n",
    "        data.index = data.index.tz_localize(None)\n",
    "\n",
    "    # Convert datetime to date-only\n",
    "    data.index = pd.to_datetime(data.index).normalize()  # Normalize to remove time part, keep only date\n",
    "\n",
    "    # Filter data within the specified date range\n",
    "    start_date = pd.to_datetime('2012-01-01')\n",
    "    end_date = pd.to_datetime('2020-12-31')\n",
    "    data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.074448Z",
     "start_time": "2024-11-15T19:55:48.072005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def prepare_data(data, look_back=60):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(scaled_data)):\n",
    "        X.append(scaled_data[i-look_back:i])\n",
    "        y.append(scaled_data[i, 0])  # Predicting the 'Close' price\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.086166Z",
     "start_time": "2024-11-15T19:55:48.080964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.100277Z",
     "start_time": "2024-11-15T19:55:48.097030Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "def train_model(model, X_train, y_train, epochs=10, batch_size=32, validation_split=0.2):\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.112331Z",
     "start_time": "2024-11-15T19:55:48.109017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def make_predictions(model, X_test, scaler):\n",
    "    predictions = model.predict(X_test)\n",
    "    return scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mse, rmse, mae\n",
    "\n",
    "# Plot results\n",
    "def plot_results(y_true, y_pred):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true, label='Actual')\n",
    "    plt.plot(y_pred, label='Predicted')\n",
    "    plt.title('LSTM Model: Actual vs Predicted Stock Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.198892Z",
     "start_time": "2024-11-15T19:55:48.125700Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Main function\n",
    "\n",
    "#     # Load data\n",
    "file_path = 'SP425CSVs/TSLA_data_with_metrics.csv'  # Replace with your CSV file name\n",
    "dataCSV = pd.read_csv(file_path)\n",
    "    \n",
    "print(dataCSV)\n",
    "\n",
    "# Select features for training\n",
    "# features = ['Close','P/E Ratio', 'P/B Ratio', 'Dividend Yield', 'Dividend Payout Ratio', #4\n",
    "#             'ROE', 'ROA', 'Beta', 'Market Capitalization', 'Revenue Growth', #5\n",
    "#             'Debt-to-Equity Ratio', 'Free Cash Flow', 'Current Ratio', 'Quick Ratio', #4\n",
    "#             'PEG Ratio', 'Standard Deviation', 'Value at Risk (VaR)', 'Sharpe Ratio', #4\n",
    "#             'Sortino Ratio', 'Maximum Drawdown', 'Downside Deviation', 'Tracking Error', #4\n",
    "#             'R-squared', 'Treynor Ratio', 'Information Ratio', 'Conditional Value at Risk (CVaR)', #4\n",
    "#             'Beta-adjusted Sharpe Ratio', 'Drawdown Duration', 'Ulcer Index', 'Jensens Alpha']#4\n",
    "features = ['Close','P/E Ratio', 'P/B Ratio', #4\n",
    "            'ROE', 'Beta', 'Revenue Growth', #5\n",
    "            'Debt-to-Equity Ratio', 'Standard Deviation', #4\n",
    "            'Maximum Drawdown', 'Downside Deviation', #4\n",
    "            'R-squared', 'Treynor Ratio', 'Conditional Value at Risk (CVaR)', #4\n",
    "            'Beta-adjusted Sharpe Ratio', 'Ulcer Index', 'Jensens Alpha']#4\n",
    "data = dataCSV[features]\n",
    "datesRev=dataCSV['Date']\n",
    "# print(datesRev)\n",
    "\n",
    "# Convert 'Date' column to UTC or remove timezone\n",
    "datesRev = pd.to_datetime(dataCSV['Date'], utc=True)  # Converts to UTC\n",
    "\n",
    "# If you prefer to remove the timezone info\n",
    "# datesRev = pd.to_datetime(dataCSV['Date']).dt.tz_convert(None)\n",
    "\n",
    "# Optionally set the 'Date' column as the index\n",
    "dataCSV.set_index(datesRev, inplace=True)\n",
    "\n",
    "# Now 'datesRev' contains the dates in datetime format without timezone issues\n",
    "# print(datesRev.head())  # To check the first few dates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.209292Z",
     "start_time": "2024-11-15T19:55:48.203757Z"
    }
   },
   "outputs": [],
   "source": [
    "data=dataCSV[features]\n",
    "data.fillna(0, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.379332Z",
     "start_time": "2024-11-15T19:55:48.256378Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, look_back=45):\n",
    "    X, y, dates = [], [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data.iloc[i:(i + look_back)].values)\n",
    "        y.append(data['Close'].iloc[i + look_back])\n",
    "        dates.append(data.index[i + look_back])\n",
    "    return np.array(X), np.array(y), np.array(dates)\n",
    "\n",
    "# Prepare your data\n",
    "data['Close'] = data['Close'].shift(-1)  # Shift Close price to predict next day's price\n",
    "data = data.dropna()  # Remove any rows with NaN values\n",
    "X, y, dates = prepare_data(data)\n",
    "\n",
    "# Split the data\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "dates_train, dates_test = dates[:split], dates[split:]\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.413054Z",
     "start_time": "2024-11-15T19:55:48.408547Z"
    }
   },
   "outputs": [],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:55:48.562645Z",
     "start_time": "2024-11-15T19:55:48.448708Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(16, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model((X_train_scaled.shape[1], X_train_scaled.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:56.953835Z",
     "start_time": "2024-11-15T19:55:48.566502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:57.072961Z",
     "start_time": "2024-11-15T19:56:57.061452Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:57.146461Z",
     "start_time": "2024-11-15T19:56:57.142449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Moving Average Filter\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:58.176850Z",
     "start_time": "2024-11-15T19:56:57.151880Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Ensure dates_test is a pandas DatetimeIndex\n",
    "dates_test = pd.to_datetime(dates_test)\n",
    "\n",
    "print(f\"Date range: {dates_test.min()} to {dates_test.max()}\")\n",
    "\n",
    "# Plot results\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates_test, y_test, label='Actual', linewidth=2)\n",
    "plt.plot(dates_test, y_pred, label='Predicted', linewidth=2)\n",
    "plt.title('LSTM Model: Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "\n",
    "# Format x-axis to show dates nicely\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "plt.gcf().autofmt_xdate()  # Rotate and align the tick labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:58.256782Z",
     "start_time": "2024-11-15T19:56:58.252695Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:58:28.696728Z",
     "start_time": "2024-11-15T19:58:28.415323Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Assuming dates_test, y_test, and y_pred are already defined\n",
    "# Ensure dates_test is a pandas DatetimeIndex\n",
    "dates_test = pd.to_datetime(dates_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Create traces for actual and predicted values\n",
    "trace_actual = go.Scatter(\n",
    "    x=dates_test,\n",
    "    y=y_test,\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(width=2)\n",
    ")\n",
    "\n",
    "trace_predicted = go.Scatter(\n",
    "    x=dates_test, \n",
    "    y=y_pred.flatten(),  # Removed the -20 adjustment to keep predictions accurate\n",
    "    mode='lines', \n",
    "    name='Predicted', \n",
    "    line=dict(width=2)\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    title='LSTM Model: Actual vs Predicted Stock Prices',\n",
    "    xaxis=dict(title='Date', tickformat='%Y-%m-%d'),\n",
    "    yaxis=dict(title='Stock Price'),\n",
    "    hovermode='x',  # Add hovermode for interactive hover\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[trace_actual,trace_predicted], layout=layout)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:58.546652Z",
     "start_time": "2024-11-15T07:50:52.959451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming dates_test, y_test, and y_pred are already defined\n",
    "# Ensure dates_test is a pandas DatetimeIndex\n",
    "dates_test = pd.to_datetime(dates_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "\n",
    "# Flatten the y-values for trace_predicted\n",
    "trace_predicted = go.Scatter(\n",
    "    line={'width': 2},\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    x=predicted_x_values,  # Assuming this is your x-axis array for predicted values\n",
    "    y=predicted_y_values.flatten()  # Flatten the 2D array to make it 1D\n",
    ")\n",
    "\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    title='LSTM Model: Predicted Stock Prices',\n",
    "    xaxis=dict(title='Date', tickformat='%Y-%m-%d'),\n",
    "    yaxis=dict(title='Stock Price'),\n",
    "    hovermode='x',  # Add hovermode for interactive hover\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[trace_actual,trace_predicted], layout=layout)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:58:36.206806Z",
     "start_time": "2024-11-15T19:58:36.183126Z"
    }
   },
   "outputs": [],
   "source": [
    "print(trace_actual,\"\\n\\n\\n\\n\",trace_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:02:41.827645Z",
     "start_time": "2024-11-15T19:58:41.215932Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"SP425CSVs/AAPL_data_with_metrics.csv\"  # Update with your file path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Feature selection\n",
    "selected_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'P/E Ratio', 'P/B Ratio',\n",
    "                     'Dividend Yield', 'ROE', 'ROA', 'Beta', 'Market Capitalization', 'Revenue Growth']\n",
    "data_selected = data[selected_features]\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data_selected)\n",
    "\n",
    "# Prepare the sequences for LSTM\n",
    "sequence_length = 60\n",
    "X, y = [], []\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    X.append(scaled_data[i-sequence_length:i])  # Last 60 days\n",
    "    y.append(scaled_data[i, 3])  # 'Close' is at index 3\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "# Build the updated LSTM model with Bidirectional and more units\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))  # Predicting the 'Close' price\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)  # Reduced learning rate\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predicted_prices = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predicted_prices)\n",
    "mape = mean_absolute_percentage_error(y_test, predicted_prices)\n",
    "\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test MAPE: {mape}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, color='blue', label='Actual Prices')\n",
    "plt.plot(predicted_prices, color='red', label='Predicted Prices')\n",
    "plt.title('Stock Price Prediction with Improved Model')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:02:48.057290Z",
     "start_time": "2024-11-15T20:02:47.991637Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T19:56:58.548589Z",
     "start_time": "2024-11-15T09:14:16.576991Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional, Input, Attention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"SP425CSVs/AAPL_data_with_metrics.csv\"  # Update with your file path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Feature selection\n",
    "selected_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'P/E Ratio', 'P/B Ratio',\n",
    "                     'Dividend Yield', 'ROE', 'ROA', 'Beta', 'Market Capitalization', 'Revenue Growth']\n",
    "data_selected = data[selected_features]\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data_selected)\n",
    "\n",
    "# Prepare sequences for multi-step prediction (5 days ahead)\n",
    "sequence_length = 90  # Adjusted sequence length to 90\n",
    "future_target = 5  # Number of days ahead to predict\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(sequence_length, len(scaled_data) - future_target):\n",
    "    X.append(scaled_data[i-sequence_length:i])  # Last 90 days\n",
    "    y.append(scaled_data[i + future_target - 1, 3])  # 'Close' price 5 days ahead\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "# Build the model with GRU layers and an Attention layer\n",
    "input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "x = Bidirectional(GRU(units=150, return_sequences=True))(input_layer)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Attention Layer: provide [query, value] as input to the Attention layer\n",
    "attention_out = Attention()([x, x])\n",
    "\n",
    "x = GRU(units=150, return_sequences=False)(attention_out)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(units=1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model with a low learning rate for stability\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predicted_prices = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predicted_prices)\n",
    "mape = mean_absolute_percentage_error(y_test, predicted_prices)\n",
    "\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test MAPE: {mape}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, color='blue', label='Actual Prices')\n",
    "plt.plot(predicted_prices, color='red', label='Predicted Prices')\n",
    "plt.title('Stock Price Prediction with Multi-step Forecast and GRU')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "# model.save(\"multi_step_attention_gru_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
