{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:15:42.056036Z",
     "start_time": "2024-11-15T20:15:42.041459Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import yfinance as yf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:15:42.095824Z",
     "start_time": "2024-11-15T20:15:42.082177Z"
    }
   },
   "outputs": [],
   "source": [
    "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "def scrape_wikipedia_sp500():\n",
    "    \"\"\"Scrape S&P 500 companies and their sectors from Wikipedia.\"\"\"\n",
    "    response = requests.get(WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "    \n",
    "    companies_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        ticker = cols[0].text.strip()\n",
    "        company_name = cols[1].text.strip()\n",
    "        sector = cols[3].text.strip()\n",
    "        companies_data.append((ticker, company_name, sector))\n",
    "    \n",
    "    return companies_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:23:09.577275Z",
     "start_time": "2024-11-15T20:15:42.111526Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sp500_sectors(companies_data):\n",
    "    \"\"\"Return a list of unique sectors.\"\"\"\n",
    "    return list(set(company[2] for company in companies_data))\n",
    "\n",
    "def get_sector_companies(sector, companies_data):\n",
    "    \"\"\"Return the list of companies belonging to a sector.\"\"\"\n",
    "    return [company[0] for company in companies_data if company[2] == sector]\n",
    "\n",
    "def download_market_cap_data(ticker, start_date, end_date):\n",
    "    \"\"\"Download the stock's market capitalization at the quarter end.\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        if df.empty:\n",
    "            print(f\"No data found for {ticker}\")\n",
    "            return None\n",
    "\n",
    "        # Calculate Market Cap = Close Price * Shares Outstanding\n",
    "        shares_outstanding = stock.info.get('sharesOutstanding', None)\n",
    "        if shares_outstanding is None:\n",
    "            print(f\"No shares outstanding data for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        df['MarketCap'] = df['Close'] * shares_outstanding\n",
    "        df = df[['MarketCap']]  # Only keep MarketCap column\n",
    "        \n",
    "        # Resample to get the last value at the end of each quarter\n",
    "        df = df.resample('QE').last()\n",
    "        df['Ticker'] = ticker  # Add ticker as a column\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_sector(sector, start_date, end_date, companies_data):\n",
    "    \"\"\"Process each sector and calculate the market cap at quarter end.\"\"\"\n",
    "    companies = get_sector_companies(sector, companies_data)\n",
    "    if len(companies) < 3:\n",
    "        print(f\"Skipping {sector} sector: Only {len(companies)} companies found.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Processing {sector} sector ({len(companies)} companies)...\")\n",
    "    print(companies)\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_ticker = {executor.submit(download_market_cap_data, ticker, start_date, end_date): ticker for ticker in companies}\n",
    "        for future in as_completed(future_to_ticker):\n",
    "            ticker, result = future_to_ticker[future], future.result()\n",
    "            if result is not None and not result.empty:\n",
    "                results.append(result)\n",
    "            time.sleep(1)  # To avoid overwhelming the Yahoo Finance API\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No valid results for {sector} sector.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Combine the results into a single DataFrame\n",
    "        combined_results = pd.concat(results)\n",
    "        combined_results.reset_index(inplace=True)  # Reset index to get Date as a column\n",
    "        combined_results.rename(columns={'index': 'Date'}, inplace=True)  # Rename the index column to Date\n",
    "        return combined_results\n",
    "    except ValueError as e:\n",
    "        print(f\"Error combining results for {sector} sector: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Set the date range from Q1 2015 to Q2 2024 (or current date if earlier)\n",
    "    start_date = pd.Timestamp('2019-09-01')\n",
    "    end_date = pd.Timestamp('2024-09-30')\n",
    "    end_date = min(end_date, pd.Timestamp.now())\n",
    "\n",
    "    # Scrape Wikipedia for S&P 500 companies and sectors\n",
    "    companies_data = scrape_wikipedia_sp500()\n",
    "\n",
    "    # Get all unique sectors\n",
    "    sectors = get_sp500_sectors(companies_data)\n",
    "\n",
    "    # Create a directory for output files\n",
    "    output_dir = \"sector_mkt_cap_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each sector\n",
    "    for sector in sectors:\n",
    "        sector_results = process_sector(sector, start_date, end_date, companies_data)\n",
    "        if sector_results is not None:\n",
    "            # Save results to CSV\n",
    "            csv_filename = os.path.join(output_dir, f\"{sector}_mkt_cap_quarter_end.csv\")\n",
    "            sector_results.to_csv(csv_filename, index=False)  # Save without index\n",
    "            print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "            # Display summary\n",
    "            print(f\"Summary for {sector} sector:\")\n",
    "            print(sector_results.head())\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        else:\n",
    "            print(f\"No results to save for {sector} sector.\")\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"All sectors processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:24:21.567009Z",
     "start_time": "2024-11-15T20:23:12.878621Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "def scrape_wikipedia_sp500():\n",
    "    \"\"\"Scrape S&P 500 companies and their sectors from Wikipedia.\"\"\"\n",
    "    response = requests.get(WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "    \n",
    "    companies_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        ticker = cols[0].text.strip()\n",
    "        company_name = cols[1].text.strip()\n",
    "        sector = cols[3].text.strip()\n",
    "        companies_data.append((ticker, company_name, sector))\n",
    "    \n",
    "    return companies_data\n",
    "\n",
    "def get_sector_companies(sector, companies_data):\n",
    "    \"\"\"Return the list of companies belonging to a sector.\"\"\"\n",
    "    return [company[0] for company in companies_data if company[2] == sector]\n",
    "\n",
    "def download_market_cap_data(ticker, start_date, end_date):\n",
    "    \"\"\"Download the stock's market capitalization at the quarter end.\"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        if df.empty:\n",
    "            return None\n",
    "\n",
    "        # Calculate Market Cap = Close Price * Shares Outstanding\n",
    "        shares_outstanding = stock.info.get('sharesOutstanding', None)\n",
    "        if shares_outstanding is None:\n",
    "            return None\n",
    "        \n",
    "        df['MarketCap'] = df['Close'] * shares_outstanding\n",
    "        df = df[['MarketCap']]  # Only keep MarketCap column\n",
    "        \n",
    "        # Resample to get the last value at the end of each quarter\n",
    "        df = df.resample('QE').last()\n",
    "        df['Ticker'] = ticker  # Add ticker as a column\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def calculate_returns(data):\n",
    "    \"\"\"Calculate quarterly returns based on market cap.\"\"\"\n",
    "    data['Return'] = data['MarketCap'].pct_change()\n",
    "    return data.dropna(subset=['Return'])\n",
    "\n",
    "def calculate_beta(sector_returns, market_returns):\n",
    "    \"\"\"Calculate beta using aligned sector and market returns.\"\"\"\n",
    "    # Align the series to have matching dates\n",
    "    aligned_returns = sector_returns.align(market_returns, join='inner')\n",
    "    aligned_sector_returns = aligned_returns[0]\n",
    "    aligned_market_returns = aligned_returns[1]\n",
    "    \n",
    "    # Calculate covariance and beta\n",
    "    covariance = np.cov(aligned_sector_returns, aligned_market_returns)[0, 1]\n",
    "    market_variance = np.var(aligned_market_returns)\n",
    "    beta = covariance / market_variance\n",
    "    return beta\n",
    "\n",
    "\n",
    "def process_sector_with_beta(sector, start_date, end_date, companies_data, market_returns):\n",
    "    \"\"\"Calculate quarterly returns and beta for a sector.\"\"\"\n",
    "    companies = get_sector_companies(sector, companies_data)\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_ticker = {executor.submit(download_market_cap_data, ticker, start_date, end_date): ticker for ticker in companies}\n",
    "        for future in as_completed(future_to_ticker):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "    if not results:\n",
    "        return None\n",
    "\n",
    "    # Combine the results into a single DataFrame\n",
    "    combined_results = pd.concat(results)\n",
    "    combined_results.reset_index(inplace=True)\n",
    "    \n",
    "    # Calculate sector returns\n",
    "    sector_returns = combined_results.groupby('Date')['MarketCap'].sum()\n",
    "    sector_returns = calculate_returns(sector_returns.to_frame())\n",
    "\n",
    "    # Calculate beta\n",
    "    beta_value = calculate_beta(sector_returns['Return'], market_returns)\n",
    "    return beta_value\n",
    "\n",
    "def main():\n",
    "    start_date = pd.Timestamp('2019-09-30')\n",
    "    end_date = pd.Timestamp('2024-09-30')\n",
    "    \n",
    "    # Scrape Wikipedia for S&P 500 companies and sectors\n",
    "    companies_data = scrape_wikipedia_sp500()\n",
    "    \n",
    "    # Get unique sectors\n",
    "    sectors = list(set(company[2] for company in companies_data))\n",
    "    \n",
    "    # Load market index data for beta calculation (assuming S&P 500)\n",
    "    market_data = yf.Ticker('^GSPC').history(start=start_date, end=end_date)\n",
    "    market_data = market_data.resample('QE').last()  # Quarterly end\n",
    "    market_data['Return'] = market_data['Close'].pct_change().dropna()\n",
    "    market_returns = market_data['Return']\n",
    "    \n",
    "    # Calculate and store sector betas\n",
    "    sector_betas = {}\n",
    "    for sector in sectors:\n",
    "        beta_value = process_sector_with_beta(sector, start_date, end_date, companies_data, market_returns)\n",
    "        if beta_value is not None:\n",
    "            sector_betas[sector] = beta_value\n",
    "    \n",
    "    # Save to CSV\n",
    "    beta_df = pd.DataFrame(sector_betas.items(), columns=['Sector', 'Beta'])\n",
    "    beta_df.to_csv('sector_beta_values.csv', index=False)\n",
    "    print(\"Sector beta values saved to sector_beta_values.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T20:24:21.840967Z",
     "start_time": "2024-11-15T20:24:21.631897Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_growth(value):\n",
    "    \"\"\"Classify YoY growth into 1, 0, or -1 based on thresholds.\"\"\"\n",
    "    if value > 5:\n",
    "        return 1\n",
    "    elif value < -5:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_yoy_growth(df, column):\n",
    "    \"\"\"Calculate YoY growth and classify based on threshold.\"\"\"\n",
    "    df[f'{column}_YoY_Growth'] = df[column].pct_change(periods=4) * 100  # YoY percentage change\n",
    "    df[f'{column}_Growth_Class'] = df[f'{column}_YoY_Growth'].apply(classify_growth)\n",
    "    df.dropna(subset=[f'{column}_YoY_Growth'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def calculate_beta_growth_covariance(df, period):\n",
    "    \"\"\"Calculate the covariance of beta growth over a specified period.\"\"\"\n",
    "    df[f'Beta_Growth_{period}_M'] = df['Beta'].pct_change(periods=period)\n",
    "    beta_covariance = df[f'Beta_Growth_{period}_M'].cov(df['Beta'])\n",
    "    return beta_covariance\n",
    "\n",
    "def calculate_sector_index_variations(df, sorted_companies, total_overperformance):\n",
    "    \"\"\"Calculate sector index and return variations between weighted and simple average index.\"\"\"\n",
    "    fractional_contribution = {company: count**2 / total_overperformance for company, count in sorted_companies}\n",
    "\n",
    "    sector_index = pd.DataFrame()\n",
    "\n",
    "    for ticker in df['Ticker'].unique():\n",
    "        company_data = df[df['Ticker'] == ticker].copy()\n",
    "\n",
    "        if ticker in fractional_contribution:\n",
    "            contribution = fractional_contribution[ticker]\n",
    "            company_data['Weighted_YoY_Growth'] = company_data['MarketCap_Growth_Class'] * contribution\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if sector_index.empty:\n",
    "            sector_index = company_data[['Date', 'Weighted_YoY_Growth']].copy()\n",
    "        else:\n",
    "            sector_index = pd.merge(sector_index, company_data[['Date', 'Weighted_YoY_Growth']],\n",
    "                                    on='Date', how='outer', suffixes=('', f'_{ticker}'))\n",
    "\n",
    "    sector_index['Weighted_Index'] = sector_index.filter(like='Weighted_YoY_Growth').sum(axis=1)\n",
    "\n",
    "    # Calculate simple average\n",
    "    simple_avg_index = df.groupby('Date')['MarketCap_Growth_Class'].mean().reset_index()\n",
    "    sector_index = pd.merge(sector_index, simple_avg_index, on='Date', how='left')\n",
    "    sector_index.rename(columns={'MarketCap_Growth_Class': 'Simple_Avg_Index'}, inplace=True)\n",
    "\n",
    "    # Calculate the difference between the weighted and simple averages\n",
    "    sector_index['Difference'] = (sector_index['Weighted_Index'] - sector_index['Simple_Avg_Index']).abs()\n",
    "\n",
    "    return sector_index[['Date', 'Weighted_Index', 'Simple_Avg_Index', 'Difference']]\n",
    "\n",
    "def calculate_variance_and_covariances(df):\n",
    "    \"\"\"Calculate variance of YoY growth and the covariances of beta growth.\"\"\"\n",
    "    # Variance of YoY growth in market cap\n",
    "    variance = df['MarketCap_Growth_Class'].var()\n",
    "\n",
    "    # Covariance for 6 months and 5 years of beta growth\n",
    "    beta_cov_6m = calculate_beta_growth_covariance(df, period=6)\n",
    "    beta_cov_5y = calculate_beta_growth_covariance(df, period=20)  # Assuming 5 years corresponds to approx. 20 quarters\n",
    "\n",
    "    return variance, beta_cov_6m, beta_cov_5y\n",
    "\n",
    "def get_sector_rankings(input_dir, output_file='sector_rankings.csv'):\n",
    "    rankings_variation = {}\n",
    "    rankings_variance = {}\n",
    "    rankings_cov_6m_beta = {}\n",
    "    rankings_cov_5y_beta = {}\n",
    "\n",
    "    for sector_file in os.listdir(input_dir):\n",
    "        if sector_file.endswith(\".csv\"):\n",
    "            sector = sector_file.replace(\"_mkt_cap_quarter_end.csv\", \"\")\n",
    "            print(f\"Processing {sector} sector...\")\n",
    "\n",
    "            # Load the CSV file and filter data for 2019-2024\n",
    "            file_path = os.path.join(input_dir, sector_file)\n",
    "            df = pd.read_csv(file_path, parse_dates=['Date'])\n",
    "\n",
    "            # Convert 'Date' to UTC\n",
    "            df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
    "\n",
    "            # Filter the data from 2019 onwards\n",
    "            df = df[df['Date'] >= pd.Timestamp('2019-01-01', tz='UTC')]\n",
    "\n",
    "            # Calculate YoY growth for MarketCap and Revenue\n",
    "            df = calculate_yoy_growth(df, 'MarketCap')\n",
    "            df = calculate_yoy_growth(df, 'Revenue')\n",
    "\n",
    "            # Calculate sector leader and fractional contributions\n",
    "            sector_leader, sorted_companies, total_overperformance = calculate_sector_leader_and_rank(df, sector)\n",
    "\n",
    "            # Calculate sector index variations\n",
    "            sector_index_variations = calculate_sector_index_variations(df, sorted_companies, total_overperformance)\n",
    "\n",
    "            # Calculate variance of YoY growth and beta covariances\n",
    "            variance, beta_cov_6m, beta_cov_5y = calculate_variance_and_covariances(df)\n",
    "\n",
    "            # Summarize the variation between weighted and simple averages\n",
    "            avg_difference = sector_index_variations['Difference'].mean()\n",
    "\n",
    "            # Save results for rankings\n",
    "            rankings_variation[sector] = avg_difference\n",
    "            rankings_variance[sector] = variance\n",
    "            rankings_cov_6m_beta[sector] = beta_cov_6m\n",
    "            rankings_cov_5y_beta[sector] = beta_cov_5y\n",
    "\n",
    "    # Create a DataFrame from the rankings\n",
    "    rankings_df = pd.DataFrame({\n",
    "        'Sector': list(rankings_variation.keys()),\n",
    "        'Variation (Weighted vs Simple Avg)': list(rankings_variation.values()),\n",
    "        'Variance of YoY Growth': list(rankings_variance.values()),\n",
    "        'Covariance of 6M Beta Growth': list(rankings_cov_6m_beta.values()),\n",
    "        'Covariance of 5Y Beta Growth': list(rankings_cov_5y_beta.values())\n",
    "    })\n",
    "\n",
    "    # Save the rankings DataFrame to CSV\n",
    "    rankings_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nRankings saved to {output_file}\")\n",
    "\n",
    "    # Optionally, print the rankings (as before)\n",
    "    print(\"\\nRanking of sectors based on variation between simple and weighted averages:\")\n",
    "    for sector, value in sorted(rankings_variation.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{sector}: {value}\")\n",
    "\n",
    "    print(\"\\nRanking of sectors based on variance of YoY growth over time:\")\n",
    "    for sector, value in sorted(rankings_variance.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{sector}: {value}\")\n",
    "\n",
    "    print(\"\\nRanking of sectors based on covariance of 6M Beta Growth:\")\n",
    "    for sector, value in sorted(rankings_cov_6m_beta.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{sector}: {value}\")\n",
    "\n",
    "    print(\"\\nRanking of sectors based on covariance of 5Y Beta Growth:\")\n",
    "    for sector, value in sorted(rankings_cov_5y_beta.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{sector}: {value}\")\n",
    "\n",
    "def main():\n",
    "    input_dir = \"merged_sector_data\"\n",
    "    get_sector_rankings(input_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "americanmarketanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
